{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0dedc6a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/nfsd/sysbiobig/bazzaccoen/tangramlit_dev\n"
     ]
    }
   ],
   "source": [
    "%cd /nfsd/sysbiobig/bazzaccoen/tangramlit_dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d5cedf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nfsd/sysbiobig/bazzaccoen/tangramlit_dev/myvenv/lib64/python3.12/site-packages/dask/dataframe/__init__.py:31: FutureWarning: The legacy Dask DataFrame implementation is deprecated and will be removed in a future version. Set the configuration option `dataframe.query-planning` to `True` or None to enable the new Dask Dataframe implementation and silence this warning.\n",
      "  warnings.warn(\n",
      "/nfsd/sysbiobig/bazzaccoen/tangramlit_dev/myvenv/lib64/python3.12/site-packages/xarray_schema/__init__.py:1: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  from pkg_resources import DistributionNotFound, get_distribution\n",
      "/nfsd/sysbiobig/bazzaccoen/tangramlit_dev/myvenv/lib64/python3.12/site-packages/anndata/utils.py:434: FutureWarning: Importing read_text from `anndata` is deprecated. Import anndata.io.read_text instead.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import tangramlit as tgl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b9c58f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scanpy as sc\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import anndata as ad\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2de4c30",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3bec075c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set data path\n",
    "data_path = \"/nfsd/sysbiobig/bazzaccoen/tangramlit_dev/data/Dataset3/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8705355b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnnData object with n_obs × n_vars = 8653 × 31053\n",
       "    var: 'gene_ids', 'feature_types'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata_sc = sc.read(data_path + \"scRNA_data.h5ad\")\n",
    "adata_sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0d75bc0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnnData object with n_obs × n_vars = 3585 × 249\n",
       "    obs: 'X', 'Y', 'Label'\n",
       "    obsm: 'spatial'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata_st = sc.read(data_path + \"seqFISH_data.h5ad\")\n",
    "adata_st"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7997d137",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "37927a07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cluster_label': None,\n",
       " 'lambda_count': 1e-05,\n",
       " 'lambda_ct_islands': 0,\n",
       " 'lambda_d': 0.001,\n",
       " 'lambda_f_reg': 1e-05,\n",
       " 'lambda_g1': 1,\n",
       " 'lambda_g2': 1,\n",
       " 'lambda_geary': 1,\n",
       " 'lambda_getis_ord': 1,\n",
       " 'lambda_l1': 1e-15,\n",
       " 'lambda_l2': 1e-18,\n",
       " 'lambda_moran': 1,\n",
       " 'lambda_neighborhood_g1': 1,\n",
       " 'lambda_r': 1e-09,\n",
       " 'lambda_sparsity_g1': 1,\n",
       " 'learning_rate': 0.1,\n",
       " 'filter': False,\n",
       " 'num_epochs': 1000,\n",
       " 'random_state': 42,\n",
       " 'target_count': None}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read config yaml\n",
    "with open(\"data/Dataset3/train_config.yaml\", \"r\") as f:\n",
    "        config = yaml.safe_load(f)\n",
    "\n",
    "config  # no cluster_label and ct_islands"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf8c71be",
   "metadata": {},
   "source": [
    "# Train/val split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4eadaade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "195 training genes:  ['irx4' 'tfdp2' 'myb' 'nr2f2' 'sin3a' 'ttf1' 'barhl1' 'foxc1' 'hoxa1'\n",
      " 'reln'] ...\n",
      "49 validation genes:  ['klf1' 'med14' 'elf1' 'foxn4' 'pin1' 'cdc6' 'xdh' 'cdc5l' 'smad3' 'irx5'] ...\n"
     ]
    }
   ],
   "source": [
    "# Get shared genes (case-insensitive)\n",
    "sc_genes = {gene.lower(): gene for gene in adata_sc.var_names}\n",
    "st_genes = {gene.lower(): gene for gene in adata_st.var_names}\n",
    "\n",
    "# Find intersection of lowercase gene names\n",
    "shared_genes_set = set(sc_genes.keys()) & set(st_genes.keys())\n",
    "shared_genes = [gene_lower for gene_lower in shared_genes_set]\n",
    "\n",
    "# Shuffle the shared genes\n",
    "shared_genes = np.array(shared_genes)\n",
    "np.random.seed(config['random_state'])\n",
    "np.random.shuffle(shared_genes)\n",
    "\n",
    "# Split into train and validation\n",
    "train_ratio = 0.8\n",
    "n_train = int(len(shared_genes) * train_ratio)\n",
    "train_genes = shared_genes[:n_train]\n",
    "val_genes = shared_genes[n_train:]\n",
    "\n",
    "print(len(train_genes), \"training genes: \", train_genes[0:10], \"...\")\n",
    "print(len(val_genes), \"validation genes: \", val_genes[0:10], \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f4afaf9",
   "metadata": {},
   "source": [
    "# Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "53261331",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:The following train/val input genes were removed with preprocessing: ['irx4', 'hoxd12', 'tfap2e', 'phox2b', 'foxn1', 'pax7', 'hoxb8', 'gata4', 'gfi1', 'foxd3'].\n",
      "WARNING:root:The following train/val input genes were removed with preprocessing: ['gata5', 'hoxb3', 'runx3', 'hnf1a'].\n",
      "\n",
      "  | Name               | Type      | Params | Mode \n",
      "---------------------------------------------------------\n",
      "0 | _density_criterion | KLDivLoss | 0      | train\n",
      "  | other params       | n/a       | 31.0 M | n/a  \n",
      "---------------------------------------------------------\n",
      "31.0 M    Trainable params\n",
      "0         Non-trainable params\n",
      "31.0 M    Total params\n",
      "124.084   Total estimated model params size (MB)\n",
      "1         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validating with 45 genes\n",
      "S matrix shape: torch.Size([8653, 45])\n",
      "G matrix shape: torch.Size([3585, 45])\n",
      "\n",
      "Validation 0: {'val_score': 0.7532742023468018, 'val_sparsity-weighted_score': 0.016755450516939163, 'val_AUC': 0.040464311838150024, 'val_entropy': 0.9390270113945007}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainig:   0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training with 185 genes\n",
      "S matrix shape: torch.Size([8653, 185])\n",
      "G matrix shape: torch.Size([3585, 185])\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "ad_map, mapper, mapper_data = tgl.map_cells_to_space(\n",
    "        adata_sc=adata_sc, \n",
    "        adata_st=adata_st, \n",
    "        train_genes_names=train_genes,\n",
    "        val_genes_names=val_genes,\n",
    "        **config,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "35387215",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read training results\n",
    "ad_map = sc.read(filename=\"/nfsd/sysbiobig/bazzaccoen/tangramlit_dev/results/adata_map_Dataset3.h5ad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1f8dc90a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Plot main loss\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mtgl\u001b[49m\u001b[43m.\u001b[49m\u001b[43mplot_loss_terms\u001b[49m\u001b[43m(\u001b[49m\u001b[43madata_map\u001b[49m\u001b[43m=\u001b[49m\u001b[43mad_map\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_key\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmain_loss\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvg_reg\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mkl_reg\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/nfsd/sysbiobig/bazzaccoen/tangramlit_dev/tangramlit/plot_utils.py:148\u001b[39m, in \u001b[36mplot_loss_terms\u001b[39m\u001b[34m(adata_map, loss_key, lambda_coeff, lambda_scale, log_scale, make_subplot, subplot_shape)\u001b[39m\n\u001b[32m    146\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mLoss term \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m not found in training_history.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    147\u001b[39m values = history[key]\n\u001b[32m--> \u001b[39m\u001b[32m148\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m values:\n\u001b[32m    149\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mLoss term \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m has empty history.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    151\u001b[39m \u001b[38;5;66;03m# to numpy\u001b[39;00m\n",
      "\u001b[31mValueError\u001b[39m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    }
   ],
   "source": [
    "# Plot main loss\n",
    "tgl.plot_loss_terms(adata_map=ad_map, loss_key=[\"main_loss\", \"vg_reg\", \"kl_reg\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f91ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Score terms\n",
    "tgl.plot_loss_terms(adata_map=ad_map, loss_key=[\"main_loss\", \"sparsity_term\", \"neighborhood_term\"], lambda_scale=False,\n",
    "                   make_subplot=True, subplot_shape=(1,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "810d5624",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LISA terms\n",
    "tgl.plot_loss_terms(adata_map=ad_map, loss_key=[\"main_loss\", \"getis_ord_term\", \"moran_term\", \"geary_term\"], \n",
    "                    lambda_scale=False, make_subplot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d60ec07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CT islands term\n",
    "tgl.plot_loss_terms(adata_map=ad_map, loss_key=\"ct_island_term\", lambda_scale=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb602f6a",
   "metadata": {},
   "source": [
    "# Validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f19b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# call trainer.validate()\n",
    "full_val = tgl.validate_mapping_experiment(mapper, mapper_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fab0c94f",
   "metadata": {},
   "source": [
    "# Sparsity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f5b0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Project all sc data onto spots\n",
    "ad_ge = tgl.project_sc_genes_onto_space(ad_map, mapper_data)\n",
    "ad_ge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d63f1e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training genes scores dataframe\n",
    "df = tgl.compare_spatial_gene_expr(ad_ge, mapper_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee5c797",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training scores panels\n",
    "tgl.plot_training_scores(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeddb761",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot polyfit on test genes\n",
    "tgl.plot_auc_curve(df)  # same as validation genes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e14c88",
   "metadata": {},
   "source": [
    "# Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c402f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write tgl.map_cells_to_space() output to .h5ad\n",
    "sc.write(filename='/nfsd/sysbiobig/bazzaccoen/tangramlit_dev/results/adata_map_Dataset3', adata=ad_map, ext='h5ad')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
